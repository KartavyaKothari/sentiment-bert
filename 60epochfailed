[nltk_data] Downloading package stopwords to
[nltk_data]     /mnt/b100/d0/kartavya/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
  0%|          | 0/60 [00:00<?, ?it/s]  2%|▏         | 1/60 [10:28<10:17:58, 628.45s/it]  3%|▎         | 2/60 [20:59<10:08:09, 629.13s/it]  5%|▌         | 3/60 [31:29<9:58:07, 629.60s/it]   7%|▋         | 4/60 [42:00<9:48:00, 630.02s/it]  8%|▊         | 5/60 [52:30<9:37:29, 629.99s/it] 10%|█         | 6/60 [1:03:01<9:27:05, 630.11s/it] 12%|█▏        | 7/60 [1:13:32<9:16:48, 630.34s/it] 13%|█▎        | 8/60 [1:24:02<9:06:18, 630.35s/it] 15%|█▌        | 9/60 [1:34:32<8:55:45, 630.31s/it] 17%|█▋        | 10/60 [1:45:03<8:45:21, 630.44s/it] 18%|█▊        | 11/60 [1:55:34<8:34:59, 630.59s/it] 20%|██        | 12/60 [2:06:04<8:24:20, 630.42s/it] 22%|██▏       | 13/60 [2:16:35<8:13:54, 630.53s/it] 23%|██▎       | 14/60 [2:27:05<8:03:26, 630.58s/it] 25%|██▌       | 15/60 [2:37:35<7:52:48, 630.40s/it] 27%|██▋       | 16/60 [2:48:05<7:42:10, 630.23s/it] 28%|██▊       | 17/60 [2:58:35<7:31:37, 630.18s/it] 30%|███       | 18/60 [3:09:05<7:21:06, 630.15s/it] 32%|███▏      | 19/60 [3:19:35<7:10:26, 629.91s/it] 33%|███▎      | 20/60 [3:30:02<6:59:20, 629.00s/it] 35%|███▌      | 21/60 [3:40:29<6:48:35, 628.61s/it] 37%|███▋      | 22/60 [3:50:57<6:37:54, 628.27s/it] 38%|███▊      | 23/60 [4:01:24<6:27:19, 628.10s/it] 40%|████      | 24/60 [4:11:53<6:16:52, 628.12s/it] 42%|████▏     | 25/60 [4:22:19<6:06:07, 627.63s/it] 43%|████▎     | 26/60 [4:32:46<5:55:32, 627.43s/it] 45%|████▌     | 27/60 [4:43:14<5:45:10, 627.58s/it] 47%|████▋     | 28/60 [4:53:41<5:34:33, 627.31s/it] 48%|████▊     | 29/60 [5:04:06<5:23:47, 626.70s/it] 50%|█████     | 30/60 [5:14:34<5:13:33, 627.12s/it] 52%|█████▏    | 31/60 [5:25:01<5:03:09, 627.21s/it] 53%|█████▎    | 32/60 [5:35:28<4:52:38, 627.11s/it] 55%|█████▌    | 33/60 [5:45:57<4:42:25, 627.62s/it] 57%|█████▋    | 34/60 [5:56:25<4:31:57, 627.59s/it] 58%|█████▊    | 35/60 [6:06:53<4:21:35, 627.84s/it] 60%|██████    | 36/60 [6:17:17<4:10:38, 626.61s/it] 62%|██████▏   | 37/60 [6:27:44<4:00:16, 626.81s/it] 63%|██████▎   | 38/60 [6:38:11<3:49:53, 626.99s/it] 65%|██████▌   | 39/60 [6:48:39<3:39:27, 627.05s/it] 67%|██████▋   | 40/60 [6:59:04<3:28:51, 626.59s/it] 68%|██████▊   | 41/60 [7:09:30<3:18:22, 626.45s/it] 70%|███████   | 42/60 [7:19:57<3:07:58, 626.59s/it] 72%|███████▏  | 43/60 [7:30:21<2:57:19, 625.84s/it] 73%|███████▎  | 44/60 [7:40:49<2:47:00, 626.26s/it] 75%|███████▌  | 45/60 [7:51:16<2:36:37, 626.50s/it] 77%|███████▋  | 46/60 [8:01:42<2:26:09, 626.39s/it] 78%|███████▊  | 47/60 [8:12:07<2:15:40, 626.17s/it] 80%|████████  | 48/60 [8:22:35<2:05:18, 626.55s/it] 82%|████████▏ | 49/60 [8:33:02<1:54:52, 626.61s/it] 83%|████████▎ | 50/60 [8:43:28<1:44:25, 626.53s/it] 85%|████████▌ | 51/60 [8:53:55<1:33:59, 626.57s/it] 87%|████████▋ | 52/60 [9:04:22<1:23:34, 626.77s/it] 88%|████████▊ | 53/60 [9:14:48<1:13:06, 626.71s/it] 90%|█████████ | 54/60 [9:25:15<1:02:39, 626.62s/it] 92%|█████████▏| 55/60 [9:35:41<52:12, 626.48s/it]   93%|█████████▎| 56/60 [9:46:08<41:46, 626.50s/it] 95%|█████████▌| 57/60 [9:56:34<31:19, 626.51s/it] 97%|█████████▋| 58/60 [10:07:01<20:53, 626.54s/it] 98%|█████████▊| 59/60 [10:17:27<10:26, 626.61s/it]100%|██████████| 60/60 [10:27:54<00:00, 626.66s/it]100%|██████████| 60/60 [10:27:54<00:00, 627.91s/it]
File read into dataframe
Converted 04 to 01
Cleaned text of stopwords
Bert tokenization complete
Total tuples 320000
Data preparation complete, training begins now

Validation accuracy: 0.7016875
Validation F1-micro score: 0.7016875
Validation Loss: 593.831240773201

Validation accuracy: 0.74375
Validation F1-micro score: 0.74375
Validation Loss: 554.2407514452934

Validation accuracy: 0.7550234375
Validation F1-micro score: 0.7550234375
Validation Loss: 543.5891804993153

Validation accuracy: 0.760515625
Validation F1-micro score: 0.760515625
Validation Loss: 537.4484732747078

Validation accuracy: 0.764828125
Validation F1-micro score: 0.764828125
Validation Loss: 533.7274952232838

Validation accuracy: 0.766875
Validation F1-micro score: 0.766875
Validation Loss: 532.1807329952717

Validation accuracy: 0.7704453125
Validation F1-micro score: 0.7704453125
Validation Loss: 529.0967042148113

Validation accuracy: 0.7718671875
Validation F1-micro score: 0.7718671875
Validation Loss: 527.9425244033337

Validation accuracy: 0.7718984375
Validation F1-micro score: 0.7718984375000001
Validation Loss: 527.6183324754238

Validation accuracy: 0.7729296875
Validation F1-micro score: 0.7729296875
Validation Loss: 526.9094293415546

Validation accuracy: 0.77509375
Validation F1-micro score: 0.7750937499999999
Validation Loss: 524.4951133728027

Validation accuracy: 0.774796875
Validation F1-micro score: 0.774796875
Validation Loss: 524.8077154755592

Validation accuracy: 0.7756484375
Validation F1-micro score: 0.7756484375
Validation Loss: 523.6508707106113

Validation accuracy: 0.7777109375
Validation F1-micro score: 0.7777109375
Validation Loss: 522.2105481922626

Validation accuracy: 0.77665625
Validation F1-micro score: 0.77665625
Validation Loss: 523.1270941495895

Validation accuracy: 0.7785859375
Validation F1-micro score: 0.7785859375
Validation Loss: 520.9169607162476

Validation accuracy: 0.7792890625
Validation F1-micro score: 0.7792890625
Validation Loss: 520.5102641582489

Validation accuracy: 0.7799609375
Validation F1-micro score: 0.7799609374999998
Validation Loss: 520.242673844099

Validation accuracy: 0.7798515625
Validation F1-micro score: 0.7798515625
Validation Loss: 519.7752479612827

Validation accuracy: 0.77975
Validation F1-micro score: 0.77975
Validation Loss: 519.8808436393738

Validation accuracy: 0.7809921875
Validation F1-micro score: 0.7809921875
Validation Loss: 519.1124780774117

Validation accuracy: 0.78159375
Validation F1-micro score: 0.78159375
Validation Loss: 518.4987992346287

Validation accuracy: 0.7819921875
Validation F1-micro score: 0.7819921875
Validation Loss: 518.0092552602291

Validation accuracy: 0.78159375
Validation F1-micro score: 0.78159375
Validation Loss: 518.073219537735

Validation accuracy: 0.781640625
Validation F1-micro score: 0.7816406249999999
Validation Loss: 518.0702574551105

Validation accuracy: 0.7824765625
Validation F1-micro score: 0.7824765625
Validation Loss: 518.0528009235859

Validation accuracy: 0.7824921875
Validation F1-micro score: 0.7824921875
Validation Loss: 517.630468159914

Validation accuracy: 0.7831796875
Validation F1-micro score: 0.7831796875
Validation Loss: 517.0333630442619

Validation accuracy: 0.7820390625
Validation F1-micro score: 0.7820390625
Validation Loss: 518.6166603863239

Validation accuracy: 0.783359375
Validation F1-micro score: 0.783359375
Validation Loss: 516.975538700819

Validation accuracy: 0.7834609375
Validation F1-micro score: 0.7834609374999999
Validation Loss: 516.5459242165089

Validation accuracy: 0.7838046875
Validation F1-micro score: 0.7838046875
Validation Loss: 516.7169246673584

Validation accuracy: 0.784109375
Validation F1-micro score: 0.784109375
Validation Loss: 516.2043186426163

Validation accuracy: 0.784453125
Validation F1-micro score: 0.784453125
Validation Loss: 516.0476565957069

Validation accuracy: 0.783890625
Validation F1-micro score: 0.783890625
Validation Loss: 517.6040072739124

Validation accuracy: 0.7853203125
Validation F1-micro score: 0.7853203125
Validation Loss: 515.9475704729557

Validation accuracy: 0.78471875
Validation F1-micro score: 0.78471875
Validation Loss: 516.2799174189568

Validation accuracy: 0.7854140625
Validation F1-micro score: 0.7854140625000001
Validation Loss: 515.8705407381058

Validation accuracy: 0.7846796875
Validation F1-micro score: 0.7846796875
Validation Loss: 516.1138748824596

Validation accuracy: 0.7845
Validation F1-micro score: 0.7844999999999999
Validation Loss: 516.0715669393539

Validation accuracy: 0.7830546875
Validation F1-micro score: 0.7830546875
Validation Loss: 517.5511608123779

Validation accuracy: 0.786015625
Validation F1-micro score: 0.786015625
Validation Loss: 515.9766122102737

Validation accuracy: 0.7852421875
Validation F1-micro score: 0.7852421875
Validation Loss: 516.3750446140766

Validation accuracy: 0.7845625
Validation F1-micro score: 0.7845625
Validation Loss: 516.3307574689388

Validation accuracy: 0.78640625
Validation F1-micro score: 0.78640625
Validation Loss: 515.393714338541

Validation accuracy: 0.7862578125
Validation F1-micro score: 0.7862578125
Validation Loss: 515.4538140594959

Validation accuracy: 0.7837578125
Validation F1-micro score: 0.7837578125
Validation Loss: 517.5056377351284

Validation accuracy: 0.786546875
Validation F1-micro score: 0.786546875
Validation Loss: 515.1836606860161

Validation accuracy: 0.786640625
Validation F1-micro score: 0.786640625
Validation Loss: 515.0309194326401

Validation accuracy: 0.784296875
Validation F1-micro score: 0.7842968749999999
Validation Loss: 517.657302737236

Validation accuracy: 0.7856328125
Validation F1-micro score: 0.7856328125
Validation Loss: 516.0529997050762

Validation accuracy: 0.7865859375
Validation F1-micro score: 0.7865859375
Validation Loss: 515.6447191536427

Validation accuracy: 0.7864296875
Validation F1-micro score: 0.7864296875
Validation Loss: 515.8367033004761

Validation accuracy: 0.7860234375
Validation F1-micro score: 0.7860234375000001
Validation Loss: 516.4585906565189

Validation accuracy: 0.784640625
Validation F1-micro score: 0.784640625
Validation Loss: 517.1678735017776

Validation accuracy: 0.7870546875
Validation F1-micro score: 0.7870546875
Validation Loss: 515.3890793919563

Validation accuracy: 0.784875
Validation F1-micro score: 0.784875
Validation Loss: 517.1828435361385

Validation accuracy: 0.7842890625
Validation F1-micro score: 0.7842890625
Validation Loss: 518.5006368458271

Validation accuracy: 0.7869765625
Validation F1-micro score: 0.7869765625
Validation Loss: 515.1896626651287

Validation accuracy: 0.7872734375
Validation F1-micro score: 0.7872734375
Validation Loss: 515.5202854573727
Traceback (most recent call last):
  File "sentiment_analyis.py", line 229, in <module>
    torch.save(model,'models/sentiment.pth')
  File "/mnt/cherry/data/kartavya/anaconda3/envs/sentiment_env/lib/python3.7/site-packages/torch/serialization.py", line 224, in save
    return _with_file_like(f, "wb", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File "/mnt/cherry/data/kartavya/anaconda3/envs/sentiment_env/lib/python3.7/site-packages/torch/serialization.py", line 147, in _with_file_like
    f = open(f, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'models/sentiment.pth'
